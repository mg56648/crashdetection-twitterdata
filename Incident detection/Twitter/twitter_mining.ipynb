{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "consumer_key = 'AUoIy5No3qjx3v3Q1S68U10qj'\n",
    "consumer_secret = '16nMbFfRF4s5QpY7MqTVuEC0O6Zx45YUcOvalVXS0mXeBZZpGc'\n",
    "access_token = '1013231814331305985-34iKKWvPXlHsaUsf7TK0ASwCOS9a9P'\n",
    "access_secret = 'R86KqIjDaPdTPpnIw3ebmb8Lho0fySZRjrBSqHh3DpDa5'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = '1013231814331305985-34iKKWvPXlHsaUsf7TK0ASwCOS9a9P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tweets\n",
    "def get_tweets(username):\n",
    "         \n",
    "        # Authorization to consumer key and consumer secret\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    " \n",
    "        # Access to user's access key and access secret\n",
    "        auth.set_access_token(access_key, access_secret)\n",
    " \n",
    "        # Calling api\n",
    "        api = tweepy.API(auth)\n",
    " \n",
    "        # 200 tweets to be extracted\n",
    "        number_of_tweets=200\n",
    "        tweets = api.user_timeline(screen_name=username)\n",
    " \n",
    "        # Empty Array\n",
    "        tmp=[] \n",
    " \n",
    "        # create array of tweet information: username, \n",
    "        # tweet id, date/time, text\n",
    "        tweets_for_csv = [tweet.text for tweet in tweets] # CSV file created \n",
    "        for j in tweets_for_csv:\n",
    " \n",
    "            # Appending tweets to the empty array tmp\n",
    "            tmp.append(j) \n",
    " \n",
    "        # Printing the tweets\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u\"Good News: NB I-35 has fully re-opened near Slaughter Ln. Drive friendly. It's too hot to deal with crashes right now. #my35 #atxtraffic\", u'Traffic update: Two NB I-35 lanes now closed near Slaughter Ln due to truck crash. Stay left, expect delays. #my35 #atxtraffic', u'Traffic alert: Two truck crash-NB I-35 right lane near Slaughter Ln. Stay left. #my35 #atxtraffic https://t.co/RGowoleVM6', u'Traffic alert: Police report SB SH 130 is closed at Cameron Rd due to crash. #atxtraffic', u'Has a HERO helped you out? Share your story with us! #HERO #atxtraffic #my35 https://t.co/sQJaeK1jLq', u'Good news! SH 45 North has reopened east of I-35. Drive friendly. #ATXTraffic', u'Update: RM 962 at SH 71 is open as crews make progress fighting the Llano County wildfire.  TxDOT has provided near\\u2026 https://t.co/pWOA6jgBf1', u\"Good news: Southbound I-35 fully open at Kyle Parkway. Drive friendly out there. It's too hot to mess with crashes. #my35 #atxtraffic\", u'Traffic alert: SB I-35 left lane closed at Kyle Parkway due to crash. Stay right, watch for emergency vehicles. #my35 #atxtraffic', u'Traffic Update: EB SH 45 North closed near Schulze Ln. Traffic can detour at the Donnell Dr exit. #atxtraffic', u'TRAFFIC ALERT: SH 45 North closed eastbound at Meister Ln due to overturned truck and fuel spill. Main lanes and to\\u2026 https://t.co/EC7TTKDEFi', u'Good news- WB RM 1431 is open near Toro Grande. #ATXTraffic', u\"Crews are making big progress on the MoPac Intersections projects. Take a bird's eye view of the La Crosse Avenue a\\u2026 https://t.co/KKLXMRtXca\", u'Traffic Alert! RM 962 at SH 71 remains closed due to brush fire in Llano County. TxDOT donating 350 gallons of fuel\\u2026 https://t.co/isT7J0y9sg', u\"#TBT - I-35 at Texas 29 in Georgetown back in August 1966. Sure doesn't look like this anymore.  #atxtraffic #my35 https://t.co/rKm5gfIJ9K\", u'Traffic alert: WB RM 1431 down to one lane at Toro Grande due to rollover crash. Expect delays. #atxtraffic', u'Good news: WB US 290 has reopened near Lamar Blvd. Drive friendly out there. #atxtraffic', u'Traffic alert: WB right lane on 290/71 Ben White near Lamar Blvd closed due to crash. The Lamar exit and exit to LP\\u2026 https://t.co/uc7wfsVZtF', u'Good News: NB I-35 past Oltorf St has reopened. #my35 #atxtraffic', u'Traffic Alert: A crash on NB I-35 just past Oltorf St has two left lanes closed. Traffic backed up past 290/71 Ben White.  #my35 #atxtraffic']\n"
     ]
    }
   ],
   "source": [
    "# Driver code\n",
    "if __name__ == '__main__':\n",
    " \n",
    "    # Here goes the twitter handle for the user\n",
    "    # whose tweets are to be extracted.\n",
    "    get_tweets(\"TxDOTAustin\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tree - does tweet have the word crash\n",
    "    # Alert/bad news? - get latitude and longitude - incident_bad\n",
    "    # update - #good news\n",
    "             #- #bad news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good News: NB I-35 has fully re-opened near Slaughter Ln. Drive friendly. It's too hot to deal with crashes right now. #my35 #atxtraffic\n",
      "Traffic update: Two NB I-35 lanes now closed near Slaughter Ln due to truck crash. Stay left, expect delays. #my35 #atxtraffic\n",
      "Traffic alert: Two truck crash-NB I-35 right lane near Slaughter Ln. Stay left. #my35 #atxtraffic https://t.co/RGowoleVM6\n",
      "Traffic alert: Police report SB SH 130 is closed at Cameron Rd due to crash. #atxtraffic\n",
      "Has a HERO helped you out? Share your story with us! #HERO #atxtraffic #my35 https://t.co/sQJaeK1jLq\n",
      "Good news! SH 45 North has reopened east of I-35. Drive friendly. #ATXTraffic\n",
      "Update: RM 962 at SH 71 is open as crews make progress fighting the Llano County wildfire.  TxDOT has provided near… https://t.co/pWOA6jgBf1\n",
      "Good news: Southbound I-35 fully open at Kyle Parkway. Drive friendly out there. It's too hot to mess with crashes. #my35 #atxtraffic\n",
      "Traffic alert: SB I-35 left lane closed at Kyle Parkway due to crash. Stay right, watch for emergency vehicles. #my35 #atxtraffic\n",
      "Traffic Update: EB SH 45 North closed near Schulze Ln. Traffic can detour at the Donnell Dr exit. #atxtraffic\n",
      "TRAFFIC ALERT: SH 45 North closed eastbound at Meister Ln due to overturned truck and fuel spill. Main lanes and to… https://t.co/EC7TTKDEFi\n"
     ]
    }
   ],
   "source": [
    "###########Tweete before one day########\n",
    "\n",
    "import datetime, time\n",
    "list1 = []\n",
    "def get_tweets(api, username):\n",
    "    \n",
    "    page = 1\n",
    "    deadend = False\n",
    "    while True:\n",
    "        tweets = api.user_timeline(username, page = page)\n",
    "\n",
    "        for tweet in tweets:\n",
    "            if (datetime.datetime.now() - tweet.created_at).days < 1:\n",
    "                #Do processing here:\n",
    "                list1.append(tweet.text.encode(\"utf-8\"))\n",
    "                print tweet.text.encode(\"utf-8\")\n",
    "            else:\n",
    "                deadend = True\n",
    "                return\n",
    "        if not deadend:\n",
    "            page+=1\n",
    "            time.sleep(500)\n",
    "\n",
    "get_tweets(api, \"TxDOTAustin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(0,len(list1)):\n",
    "    URLless_string = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', list1[i])\n",
    "    list1[i] = URLless_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalised, text plus words, check next two words, if next two words belong in dictionary then ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'col':list1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'] = df['col'].astype(str)\n",
    "df['col'] = df['col'].str.replace(\"\\'\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['tokens'] = [word_tokenize(i) for i in df['col']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop =stopwords.words('english')\n",
    "#df['sentence'] = df['sentence'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/manojgedela/anaconda2/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "##STREETS OF AUSTIN##\n",
    "url=\"https://geographic.org/streetview/usa/tx/austin.html\"\n",
    "import urllib\n",
    "m = urllib.urlopen(url)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(m)\n",
    "s = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###list of streets###\n",
    "streets_list = [i.string for i in s]\n",
    "a = [0,1,2]\n",
    "for i in a:\n",
    "    del streets_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Numbers before and after streets###\n",
    "###n-grams, combine two and three words###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Update: RM 962 at SH 71 is open as crews make ...</td>\n",
       "      <td>[Update, :, RM, 962, at, SH, 71, is, open, as,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good news: Southbound I-35 fully open at Kyle ...</td>\n",
       "      <td>[Good, news, :, Southbound, I-35, fully, open,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Traffic alert: SB I-35 left lane closed at Kyl...</td>\n",
       "      <td>[Traffic, alert, :, SB, I-35, left, lane, clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Traffic Update: EB SH 45 North closed near Sch...</td>\n",
       "      <td>[Traffic, Update, :, EB, SH, 45, North, closed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TRAFFIC ALERT: SH 45 North closed eastbound at...</td>\n",
       "      <td>[TRAFFIC, ALERT, :, SH, 45, North, closed, eas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  col  \\\n",
       "6   Update: RM 962 at SH 71 is open as crews make ...   \n",
       "7   Good news: Southbound I-35 fully open at Kyle ...   \n",
       "8   Traffic alert: SB I-35 left lane closed at Kyl...   \n",
       "9   Traffic Update: EB SH 45 North closed near Sch...   \n",
       "10  TRAFFIC ALERT: SH 45 North closed eastbound at...   \n",
       "\n",
       "                                               tokens  \n",
       "6   [Update, :, RM, 962, at, SH, 71, is, open, as,...  \n",
       "7   [Good, news, :, Southbound, I-35, fully, open,...  \n",
       "8   [Traffic, alert, :, SB, I-35, left, lane, clos...  \n",
       "9   [Traffic, Update, :, EB, SH, 45, North, closed...  \n",
       "10  [TRAFFIC, ALERT, :, SH, 45, North, closed, eas...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop =stopwords.words('english')\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###onegrams list###\n",
    "tokens = []\n",
    "unigrams = []\n",
    "for i in range(df.shape[0]):\n",
    "    tokens = df.iloc[i,1]\n",
    "    unigrams.append([(tokens[i]) for i in range(0,len(tokens))])\n",
    "unigrams = [item for sublist in unigrams for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###bigrams list###\n",
    "tokens = []\n",
    "bigrams = []\n",
    "for i in range(df.shape[0]):\n",
    "    tokens = df.iloc[i,1]\n",
    "    bigrams.append([(tokens[i]+' '+tokens[i+1]) for i in range(0,len(tokens)-1)])\n",
    "bigrams = [item for sublist in bigrams for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###3grams list###\n",
    "tokens = []\n",
    "three_grams = []\n",
    "for i in range(df.shape[0]):\n",
    "    tokens = df.iloc[i,1]\n",
    "    three_grams.append([(tokens[i-1]+' '+tokens[i]+tokens[i+1]) for i in range(0,len(tokens)-1)])\n",
    "three_grams = [item for sublist in three_grams for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_without_numbers = []\n",
    "for i in range(0,len(streets_list)):\n",
    "    streets_without_numbers.append(' '.join(s for s in streets_list[i].split() if not any(c.isdigit() for c in s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_without_numbers_clean = []\n",
    "import re\n",
    "for i in range(0,len(streets_without_numbers)):\n",
    "    streets_without_numbers_clean.append(re.sub(r'\\b\\w{1,2}\\b', '', streets_without_numbers[i]))\n",
    "\n",
    "streets_without_numbers_clean = [x.strip() for x in streets_without_numbers_clean if x.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "location_list = []\n",
    "for i in range(0,len(streets_without_numbers_clean)):\n",
    "    for j in range(0,len(unigrams)):\n",
    "        if streets_without_numbers_clean[i] == unigrams[j]:\n",
    "            if streets_without_numbers_clean[i] not in location_list:\n",
    "                 location_list.append(streets_without_numbers_clean[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = ['Avenue','-','Texas','North','Main']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Cameron', u'Llano', u'Parkway']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in clean_words:\n",
    "    if i in location_list:\n",
    "        location_list.remove(i)\n",
    "location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##if bigrams match, then consider that for the location##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.latlong.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'send_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-27d66b4752d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputElement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"home_search_input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minputElement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cameron austin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0minputElement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'send_keys'"
     ]
    }
   ],
   "source": [
    "inputElement = driver.find_elements_by_id(\"home_search_input\")\n",
    "inputElement.send_keys('cameron austin')\n",
    "inputElement.send_keys(Keys.ENTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
