{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    " \n",
    "consumer_key = 'AUoIy5No3qjx3v3Q1S68U10qj'\n",
    "consumer_secret = '16nMbFfRF4s5QpY7MqTVuEC0O6Zx45YUcOvalVXS0mXeBZZpGc'\n",
    "access_token = '1013231814331305985-34iKKWvPXlHsaUsf7TK0ASwCOS9a9P'\n",
    "access_secret = 'R86KqIjDaPdTPpnIw3ebmb8Lho0fySZRjrBSqHh3DpDa5'\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = '1013231814331305985-34iKKWvPXlHsaUsf7TK0ASwCOS9a9P'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracted tweets from 2016 to 2018 from the folder 'GetOldTweets-python-master' <br>\n",
    "Using the command ' python Exporter.py --near Austin --within 30mi --since 2016-01-10 --until 2018-09-10' in splits. <br>\n",
    "Combine all these files into one single file <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Read and Stitch tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del_cols = ['retweets','favorites','id','permalink']\n",
    "cols = list(pd.read_csv(\"16_01-17_01.csv\", nrows =1,sep=';'))\n",
    "df1 = pd.read_csv(\"16_01-17_01.csv\", error_bad_lines=False,sep=';',usecols =[i for i in cols if i not in del_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['retweets','favorites','id','permalink']\n",
    "cols = list(pd.read_csv(\"17_07-17_01.csv\", nrows =1,sep=';'))\n",
    "df2 = pd.read_csv(\"17_07-17_01.csv\", error_bad_lines=False,sep=';',usecols =[i for i in cols if i not in del_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['retweets','favorites','id','permalink']\n",
    "cols = list(pd.read_csv(\"17_10-17_7.csv\", nrows =1,sep=';'))\n",
    "df3 = pd.read_csv(\"17_10-17_7.csv\", error_bad_lines=False,sep=';',usecols =[i for i in cols if i not in del_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['retweets','favorites','id','permalink']\n",
    "cols = list(pd.read_csv(\"18_01-17_10.csv\", nrows =1,sep=';'))\n",
    "df4 = pd.read_csv(\"18_01-17_10.csv\", error_bad_lines=False,sep=';',usecols =[i for i in cols if i not in del_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_cols = ['retweets','favorites','id','permalink']\n",
    "cols = list(pd.read_csv(\"18_01-18_09.csv\", nrows =1,sep=';'))\n",
    "df5 = pd.read_csv(\"18_01-18_09.csv\", error_bad_lines=False,sep=';',usecols =[i for i in cols if i not in del_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2,df3,df4,df5],ignore_index=True)\n",
    "del df1,df2,df3,df4,df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>geo</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AustinTracyW</td>\n",
       "      <td>2017-01-08 17:59</td>\n",
       "      <td># leftovers chicken fajita and grilled veggies...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adlongoria</td>\n",
       "      <td>2017-01-08 17:58</td>\n",
       "      <td>I'm at Violet Crown Cinema - @ vccinema for Ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supesec</td>\n",
       "      <td>2017-01-08 17:58</td>\n",
       "      <td>The Impalers # thisisaustinnotthatgreat # thei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Hotel</td>\n",
       "      <td># #</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sweetpeachyprop</td>\n",
       "      <td>2017-01-08 17:58</td>\n",
       "      <td>Fantastic dinner noms!!! (@Hyde Park Bar &amp; Gri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Hyde @</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JawnRedcorn</td>\n",
       "      <td>2017-01-08 17:56</td>\n",
       "      <td>he's all up in my George Foreman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username              date  \\\n",
       "0     AustinTracyW  2017-01-08 17:59   \n",
       "1       adlongoria  2017-01-08 17:58   \n",
       "2          supesec  2017-01-08 17:58   \n",
       "3  sweetpeachyprop  2017-01-08 17:58   \n",
       "4      JawnRedcorn  2017-01-08 17:56   \n",
       "\n",
       "                                                text  geo mentions hashtags  \n",
       "0  # leftovers chicken fajita and grilled veggies...  NaN      NaN        #  \n",
       "1  I'm at Violet Crown Cinema - @ vccinema for Ma...  NaN        @      NaN  \n",
       "2  The Impalers # thisisaustinnotthatgreat # thei...  NaN   @Hotel      # #  \n",
       "3  Fantastic dinner noms!!! (@Hyde Park Bar & Gri...  NaN  @Hyde @      NaN  \n",
       "4                   he's all up in my George Foreman  NaN      NaN      NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Tweets from  2016-01-10 to 2018-09-10 are copied to the df dataframe###\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132965, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###There are a total of 1,132,965 tweets for the two years\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to one single file\n",
    "df.to_csv('Total_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.1 Web-scraping news articles to find crash related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "###2018 fatalities###\n",
    "list1 = []\n",
    "urls = [\"https://talk1370.radio.com/tag/2018-traffic-fatalities\",\\\n",
    "      \"https://talk1370.radio.com/tag/2018-traffic-fatalities?page=0%2C1\",\\\n",
    "      \"https://talk1370.radio.com/tag/2018-traffic-fatalities?page=0%2C2\",\\\n",
    "      \"https://talk1370.radio.com/tag/2018-traffic-fatalities?page=0%2C3\"]\n",
    "\n",
    "def getURL(page):\n",
    "    \"\"\"\n",
    "    :param page: html of web page (here: Python home page) \n",
    "    :return: urls in that page \n",
    "    \"\"\"\n",
    "    start_link = page.find(\"a href\")\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find('\"', start_link)\n",
    "    end_quote = page.find('\"', start_quote + 1)\n",
    "    url = page[start_quote + 1: end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse html\n",
    "    page = str(BeautifulSoup(response.content))\n",
    "\n",
    "    while True:\n",
    "        url, n = getURL(page)\n",
    "        page = page[n:]\n",
    "        if url:\n",
    "            if url.startswith('/articles'):\n",
    "                list1.append(url)\n",
    "        else:\n",
    "            break\n",
    "list1 = [el for i, el in enumerate(list1) if el not in list1[:i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(list1)):\n",
    "    list1[i] = 'https://talk1370.radio.com'+list1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "list2 = []\n",
    "for i in range(0,len(list1)-1):\n",
    "    url = list1[i]\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    list2.append(article.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C1\",\\\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C1\",\\\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C2\",\\\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C3\",\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C4\",\\\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C5\",\\\n",
    "      \"https://talk1370.radio.com/tag/2017-traffic-fatalities?page=0%2C6\"]\n",
    "list1 = []\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # parse html\n",
    "    page = str(BeautifulSoup(response.content))\n",
    "\n",
    "    while True:\n",
    "        url, n = getURL(page)\n",
    "        page = page[n:]\n",
    "        if url:\n",
    "            if url.startswith('/articles'):\n",
    "                list1.append(url)\n",
    "        else:\n",
    "            break\n",
    "list1 = [el for i, el in enumerate(list1) if el not in list1[:i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(list1)):\n",
    "    list1[i] = 'https://talk1370.radio.com'+list1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(list1)):\n",
    "    url = list1[i]\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    #article.parse()\n",
    "    list2.append(article.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(0,len(list2)):\n",
    "    list2[i] = list2[i].replace(\"\\\\n\",\"\")\n",
    "    list2[i] = re.sub(\"\\s*-\\s*\", \"\", list2[i])\n",
    "    list2[i] = re.sub('\\W+',' ', list2[i] )\n",
    "    list2[i] = re.sub(r'\\b\\w{1,2}\\b', '', list2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'col':list2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('talk1370_articles.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter \n",
    "df1 = pd.read_csv('talk1370_articles.csv')\n",
    "#df1.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "list3 = Counter(\" \".join(df1[\"col\"]).split()).most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4 = []\n",
    "for i in range(0,len(list3)):\n",
    "    list4.append(list3[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english')) \n",
    "list4 = [w for w in list4 if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'col':list4})\n",
    "df1.to_csv('frequent_words.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('frequent_words.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 Transportation and safety related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.3 Existing Annotated Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "df = pd.read_csv('Total_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove urls##\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['text'] = df['text'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##remove special characters##\n",
    "import re\n",
    "df['text'] = df['text'].map(lambda x: re.sub(r'\\W+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "df['text'] = [word_tokenize(i) for i in df['text']]\n",
    "stop =stopwords.words('english')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if len(item)>2]) #remove this and test again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###crash related words among the frequent word list###\n",
    "# list1 = ['Austin','crash','Police','scene','man','deceased','dead','morning','county','AustinTravis','Travis',\\\n",
    "#         'pronounced','accident','vehicle','traffic','block','injuries','struck','driver','male','fatal',\\\n",
    "#         'following','happened','investigation','reported','night','South','victim','transported','Medics',\\\n",
    "#         'Interstate','lanes','time','Southbound','died','road','northbound','APD','bus','boulevard','vehicles',\\\n",
    "#         'east','north','south','pedestrian','stop','Seton','Drive','truck','Hospital','Highway',\\\n",
    "#         'area','collision','incident','killed','injured','woman','afternoon','Lamar','traveling','southeast',\\\n",
    "#         'Street','arrived','hit','fatality']\n",
    "list1 = ['crash','Police','scene','deceased','dead','pronounced','county','accident','vehicle','traffic','block',\\\n",
    "         'injuries','struck','driver','fatal','following','happened','investigation','reported','victim','transported',\\\n",
    "         'Medics','Interstate','lanes','time','Southbound','died','road','northbound','APD','boulevard','vehicles',\\\n",
    "        'pedestrian','stop','Drive','truck','Hospital','Highway',\\\n",
    "        'area','collision','incident','killed','injured','Lamar','traveling','southeast',\\\n",
    "        'Street','arrived','hit','fatality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indices of tweets that don't have any words related to crash\n",
    "list2 = []\n",
    "a = 0\n",
    "for i in df['text'].index:\n",
    "    a = len(set(list1) & set(df['text'][i]))\n",
    "    if a==0:\n",
    "        list2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132965, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.index[list2],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84480, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Filtered_tweets.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subset = df.sample(n=1000)\n",
    "random_subset.to_csv('random2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subset = df.sample(n=1000)\n",
    "random_subset.to_csv('random3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subset = df.sample(n=1000)\n",
    "random_subset.to_csv('random4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_subset = df.sample(n=1000)\n",
    "random_subset.to_csv('random5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_subset = df.sample(n=1000)\n",
    "# random_subset.to_csv('random1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Some of the tweets have information about disabled vehicles. (With the hashtag ATXTraffic) <br>\n",
    "-- Most of the accidents seem to be having hashtags (use this as a feature!!) <br>\n",
    "-- Remove the word 'ATXtraffic' and check how many tweets are there by users <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Annotations for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "r1 = pd.read_csv('random1.csv')\n",
    "r1['Y/N'] = r1['Y/N'].astype(str)\n",
    "r1 = r1[r1['Y/N'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'ATXtraffic']\", 182),\n",
       " (\"'Austin',\", 135),\n",
       " (\"['Accident',\", 127),\n",
       " (\"'traffic',\", 83),\n",
       " (\"'back',\", 83),\n",
       " (\"'delay',\", 75),\n",
       " (\"'mins',\", 65),\n",
       " (\"'stop',\", 60),\n",
       " (\"'accident',\", 58),\n",
       " (\"'Blvd',\", 41),\n",
       " (\"'reported',\", 39),\n",
       " (\"'near',\", 37),\n",
       " (\"'Travis',\", 33),\n",
       " (\"'cleared',\", 31),\n",
       " (\"['Serious',\", 24),\n",
       " (\"'Lamar',\", 24),\n",
       " (\"'183',\", 20),\n",
       " (\"'approaching',\", 17),\n",
       " (\"'290',\", 15),\n",
       " (\"'Ave',\", 15)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "Counter(\" \".join(r1[\"text\"]).split()).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- Out of the first random 1000 tweets, 195 are related to crashes, and 182 of them are from the ATXtraffic twitter account! <br>\n",
    "-- Disabled vehicles, vehicles on fire, overturned etc. Accident - good news/bad news?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "r2 = pd.read_csv('random2.csv')\n",
    "r2['Y/N'] = r2['Y/N'].astype(str)\n",
    "r2 = r2[r2['Y/N'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'ATXtraffic']\", 236),\n",
       " (\"['Accident',\", 158),\n",
       " (\"'Austin',\", 157),\n",
       " (\"'traffic',\", 107),\n",
       " (\"'back',\", 107),\n",
       " (\"'delay',\", 95),\n",
       " (\"'accident',\", 82),\n",
       " (\"'mins',\", 82),\n",
       " (\"'stop',\", 68),\n",
       " (\"'Blvd',\", 59),\n",
       " (\"'reported',\", 49),\n",
       " (\"'Travis',\", 49),\n",
       " (\"'cleared',\", 45),\n",
       " (\"'near',\", 38),\n",
       " (\"'183',\", 35),\n",
       " (\"'Lamar',\", 33),\n",
       " (\"['Serious',\", 30),\n",
       " (\"'Mopac',\", 28),\n",
       " (\"['Major',\", 27),\n",
       " (\"'slow',\", 24),\n",
       " (\"'290',\", 19),\n",
       " (\"['Injury',\", 19),\n",
       " (\"'Ave',\", 19),\n",
       " (\"'Hwy',\", 17),\n",
       " (\"'approaching',\", 16),\n",
       " (\"'stopped',\", 15),\n",
       " (\"'blocked',\", 13),\n",
       " (\"'William',\", 13),\n",
       " (\"'Cannon',\", 13),\n",
       " (\"'Pkwy',\", 12),\n",
       " (\"'lane',\", 12),\n",
       " (\"'Airport',\", 12),\n",
       " (\"'Rundberg',\", 11),\n",
       " (\"'51st',\", 11),\n",
       " (\"'Oltorf',\", 11),\n",
       " (\"'Springs',\", 10),\n",
       " (\"'Cesar',\", 10),\n",
       " (\"'Chavez',\", 10),\n",
       " (\"'min',\", 10),\n",
       " (\"'Ben',\", 10),\n",
       " (\"'White',\", 10),\n",
       " (\"'left',\", 9),\n",
       " (\"'Parmer',\", 9),\n",
       " (\"'360',\", 9),\n",
       " (\"'Boulevard',\", 8),\n",
       " (\"'Braker',\", 8),\n",
       " (\"'Manor',\", 8),\n",
       " (\"'Service',\", 8),\n",
       " (\"'2222',\", 7),\n",
       " (\"'due',\", 7),\n",
       " (\"'130',\", 7),\n",
       " (\"'east',\", 6),\n",
       " (\"'Bee',\", 6),\n",
       " (\"'right',\", 6),\n",
       " (\"'lanes',\", 6),\n",
       " (\"'Barton',\", 6),\n",
       " (\"'620',\", 6),\n",
       " (\"'973',\", 6),\n",
       " (\"'Riverside',\", 6),\n",
       " (\"'Anderson',\", 6),\n",
       " (\"'Caves',\", 5),\n",
       " (\"'Howard',\", 5),\n",
       " (\"'two',\", 5),\n",
       " (\"'Wells',\", 5),\n",
       " (\"'Branch',\", 5),\n",
       " (\"'Manchaca',\", 5),\n",
       " (\"'1626',\", 5),\n",
       " (\"'Pflugerville',\", 5),\n",
       " (\"'Grand',\", 5),\n",
       " (\"'Slaughter',\", 5),\n",
       " (\"'DelValle',\", 5),\n",
       " (\"['Closed',\", 4),\n",
       " (\"'Burnet',\", 4),\n",
       " (\"'12th',\", 4),\n",
       " (\"'Duval',\", 4),\n",
       " (\"'Burleson',\", 4),\n",
       " (\"'Steck',\", 4),\n",
       " (\"'ramp',\", 4),\n",
       " (\"'Woodward',\", 4),\n",
       " (\"'River',\", 4),\n",
       " (\"'Spicewood',\", 4),\n",
       " (\"'Pky',\", 4),\n",
       " (\"'Woodland',\", 4),\n",
       " (\"'crash',\", 4),\n",
       " (\"'Bluff',\", 3),\n",
       " (\"'Falls',\", 3),\n",
       " (\"'Pecan',\", 3),\n",
       " (\"'Koenig',\", 3),\n",
       " (\"'Pleasant',\", 3),\n",
       " (\"'Vly',\", 3),\n",
       " (\"'mins']\", 3),\n",
       " (\"'6th',\", 3),\n",
       " (\"'Skwy',\", 3),\n",
       " (\"'Dee',\", 3),\n",
       " (\"'Gabriel',\", 3),\n",
       " (\"'Collins',\", 3),\n",
       " (\"'1st',\", 3),\n",
       " (\"'Interstate',\", 3),\n",
       " (\"'Shelby',\", 3),\n",
       " (\"'Red',\", 3),\n",
       " (\"'969',\", 3),\n",
       " (\"'Enfield',\", 3),\n",
       " (\"'Ranch',\", 3),\n",
       " (\"'Yager',\", 3),\n",
       " (\"'McKinney',\", 2),\n",
       " (\"'Park',\", 2),\n",
       " (\"'38th',\", 2),\n",
       " (\"'Elroy',\", 2),\n",
       " (\"'south',\", 2),\n",
       " (\"'Cameron',\", 2),\n",
       " (\"'Chicon',\", 2),\n",
       " (\"'Frontage',\", 2),\n",
       " (\"'Research',\", 2),\n",
       " (\"'Westover',\", 2),\n",
       " (\"'SoutheastAustin',\", 2),\n",
       " (\"'Presidential',\", 2),\n",
       " (\"'Martin',\", 2),\n",
       " (\"'Luther',\", 2),\n",
       " (\"'King',\", 2),\n",
       " (\"'1327',\", 2),\n",
       " (\"'Rutherford',\", 2),\n",
       " (\"'Pfulgerville',\", 2),\n",
       " (\"'blocks',\", 2),\n",
       " (\"'Stassney',\", 2),\n",
       " (\"'Thornberry',\", 2),\n",
       " (\"'Trail',\", 2),\n",
       " (\"'Market',\", 2),\n",
       " (\"'734',\", 2),\n",
       " (\"'McNeil',\", 2),\n",
       " (\"'Windsor',\", 2),\n",
       " (\"'closed',\", 2),\n",
       " (\"'Berkman',\", 2),\n",
       " (\"'Burch',\", 2),\n",
       " (\"'685',\", 2),\n",
       " (\"'Rey',\", 2),\n",
       " (\"'open',\", 2),\n",
       " (\"'Austin_Police']\", 2),\n",
       " (\"'vehicle',\", 2),\n",
       " (\"'Kramer',\", 2),\n",
       " (\"'Colton',\", 1),\n",
       " (\"'CedarPark',\", 1),\n",
       " (\"'Lakeline',\", 1),\n",
       " (\"'Cir',\", 1),\n",
       " (\"'Teri',\", 1),\n",
       " (\"'Metric',\", 1),\n",
       " (\"'Cedar',\", 1),\n",
       " (\"'Bend',\", 1),\n",
       " (\"'BeeCave',\", 1),\n",
       " (\"'Medical',\", 1),\n",
       " (\"'Pearce',\", 1),\n",
       " (\"'Monarch',\", 1),\n",
       " (\"'Wayne',\", 1),\n",
       " (\"'Riddell',\", 1),\n",
       " (\"'Berrywood',\", 1),\n",
       " (\"'Fallwell',\", 1),\n",
       " (\"'Toll',\", 1),\n",
       " (\"'Jollyville',\", 1),\n",
       " (\"'Pond',\", 1),\n",
       " (\"'2nd',\", 1),\n",
       " (\"'Ctr',\", 1),\n",
       " (\"'Rdg',\", 1),\n",
       " (\"['Rollover',\", 1),\n",
       " (\"'41st',\", 1),\n",
       " (\"'clear',\", 1),\n",
       " (\"'Lockhart',\", 1),\n",
       " (\"'Shoreline',\", 1),\n",
       " (\"'express',\", 1),\n",
       " (\"'Caves']\", 1),\n",
       " (\"'auto',\", 1),\n",
       " (\"'pedestrian',\", 1),\n",
       " (\"'Gate',\", 1),\n",
       " (\"'Cullen',\", 1),\n",
       " (\"'Johnny',\", 1),\n",
       " (\"'Morris',\", 1),\n",
       " (\"'Loyola',\", 1),\n",
       " (\"'Guadalupe',\", 1),\n",
       " (\"'45th',\", 1),\n",
       " (\"'Lakewood',\", 1),\n",
       " (\"'service',\", 1),\n",
       " (\"'Brodie',\", 1),\n",
       " (\"'Harold',\", 1),\n",
       " (\"'Green',\", 1),\n",
       " (\"'Georgian',\", 1),\n",
       " (\"'Congress',\", 1),\n",
       " (\"'Mckenzie',\", 1),\n",
       " (\"'29th',\", 1),\n",
       " (\"'Heatherwilde',\", 1),\n",
       " (\"'10th',\", 1),\n",
       " (\"'Toomey',\", 1),\n",
       " (\"'Alexander',\", 1),\n",
       " (\"'Decker',\", 1),\n",
       " (\"'Far',\", 1),\n",
       " (\"'812',\", 1),\n",
       " (\"'Creedmoor',\", 1),\n",
       " (\"'Oak',\", 1),\n",
       " (\"'Knoll',\", 1),\n",
       " (\"'Brandt',\", 1),\n",
       " (\"'2244',\", 1),\n",
       " (\"'north',\", 1),\n",
       " (\"'Bolm',\", 1),\n",
       " (\"'Hamilton',\", 1),\n",
       " (\"'Pool',\", 1),\n",
       " (\"'Crumley',\", 1),\n",
       " (\"'Comanche',\", 1),\n",
       " (\"'Rutland',\", 1),\n",
       " (\"'Mckinney',\", 1),\n",
       " (\"'Susquehanna',\", 1),\n",
       " (\"'Tomanet',\", 1),\n",
       " (\"'Lamplight',\", 1),\n",
       " (\"'Village',\", 1),\n",
       " (\"['RRTraffic',\", 1),\n",
       " (\"'Northbound',\", 1),\n",
       " (\"'Hester',\", 1),\n",
       " (\"'Crossing',\", 1),\n",
       " (\"'exit',\", 1),\n",
       " (\"'252B',\", 1),\n",
       " (\"'dump',\", 1),\n",
       " (\"'truck',\", 1),\n",
       " (\"'Traffic']\", 1),\n",
       " (\"'1431',\", 1),\n",
       " (\"'Ross',\", 1),\n",
       " (\"'Pascal',\", 1),\n",
       " (\"'Colorado',\", 1),\n",
       " (\"'Bastrop',\", 1),\n",
       " (\"'Burch']\", 1),\n",
       " (\"'Gregg',\", 1),\n",
       " (\"'Bluestein',\", 1),\n",
       " (\"['Fatality',\", 1),\n",
       " (\"'one',\", 1),\n",
       " (\"'getting',\", 1),\n",
       " (\"'138']\", 1),\n",
       " (\"'HudsonBend',\", 1),\n",
       " (\"'west',\", 1),\n",
       " (\"'Quinlan',\", 1),\n",
       " (\"'Old',\", 1),\n",
       " (\"'Kimbro',\", 1),\n",
       " (\"'Upper',\", 1),\n",
       " (\"'Deck',\", 1),\n",
       " (\"'Westbank',\", 1),\n",
       " (\"'Stoneridge',\", 1),\n",
       " (\"'8th',\", 1),\n",
       " (\"'Thompson',\", 1),\n",
       " (\"'Saint',\", 1),\n",
       " (\"'John',\", 1),\n",
       " (\"'Montopolis',\", 1),\n",
       " (\"'Garfield',\", 1),\n",
       " (\"'Dessau',\", 1),\n",
       " (\"'Applegate',\", 1),\n",
       " (\"'Lakeway',\", 1),\n",
       " (\"'Aria',\", 1),\n",
       " (\"'Cabela',\", 1),\n",
       " (\"'Farm',\", 1),\n",
       " (\"'Springdale',\", 1),\n",
       " (\"'Lavaca',\", 1),\n",
       " (\"'15th',\", 1),\n",
       " (\"['Crash',\", 1),\n",
       " (\"'3000',\", 1),\n",
       " (\"'blk',\", 1),\n",
       " (\"'Roadway',\", 1),\n",
       " (\"'WC2',\", 1),\n",
       " (\"'Convict',\", 1),\n",
       " (\"'Breezy',\", 1),\n",
       " (\"'Pass',\", 1),\n",
       " (\"['Fatal',\", 1),\n",
       " (\"'5105',\", 1),\n",
       " (\"'Poinciana']\", 1),\n",
       " (\"'Texas',\", 1),\n",
       " (\"'Oaks',\", 1),\n",
       " (\"'shoulder',\", 1),\n",
       " (\"['Vehicle',\", 1),\n",
       " (\"'rescue',\", 1),\n",
       " (\"'CedarCreek',\", 1),\n",
       " (\"'Hyatt',\", 1),\n",
       " (\"'Lost',\", 1),\n",
       " (\"'Pines',\", 1),\n",
       " (\"'241',\", 1),\n",
       " (\"'Stoney',\", 1),\n",
       " (\"'Brook']\", 1),\n",
       " (\"['Canine',\", 1),\n",
       " (\"'chaos',\", 1),\n",
       " (\"'sxsw2018',\", 1),\n",
       " (\"'vodkafordogpeople',\", 1),\n",
       " (\"'Rainey',\", 1),\n",
       " (\"'Street',\", 1),\n",
       " (\"'Historic',\", 1),\n",
       " (\"'District']\", 1),\n",
       " (\"['Love',\", 1),\n",
       " (\"'adventures',\", 1),\n",
       " (\"'even',\", 1),\n",
       " (\"'though',\", 1),\n",
       " (\"'raining',\", 1),\n",
       " (\"'entire',\", 1),\n",
       " (\"'time']\", 1),\n",
       " (\"'wreck',\", 1),\n",
       " (\"'Mary',\", 1),\n",
       " (\"['Overturned',\", 1),\n",
       " (\"'Broadmeade',\", 1),\n",
       " (\"['ATXtraffic',\", 1),\n",
       " (\"'Ofcs',\", 1),\n",
       " (\"'responding',\", 1),\n",
       " (\"'I35',\", 1),\n",
       " (\"'Svrd',\", 1),\n",
       " (\"'San',\", 1),\n",
       " (\"'Marcos',\", 1),\n",
       " (\"'Not',\", 1),\n",
       " (\"'blocking',\", 1),\n",
       " (\"'unk',\", 1),\n",
       " (\"'injuries',\", 1),\n",
       " (\"'WC5',\", 1),\n",
       " (\"['Closure',\", 1),\n",
       " (\"'overturned',\", 1),\n",
       " (\"'Mccall',\", 1),\n",
       " (\"'AustinEastSide',\", 1),\n",
       " (\"'SouthAustin',\", 1),\n",
       " (\"'Steiner',\", 1),\n",
       " (\"'Cumberland',\", 1),\n",
       " (\"'35th',\", 1),\n",
       " (\"'Lafayette',\", 1),\n",
       " (\"['One',\", 1),\n",
       " (\"'direction',\", 1),\n",
       " (\"'Serene',\", 1),\n",
       " (\"'Hills',\", 1),\n",
       " (\"'atxtraffic',\", 1),\n",
       " (\"'TxDOTAustin']\", 1),\n",
       " (\"'entrance',\", 1),\n",
       " (\"'Ohlen',\", 1),\n",
       " (\"'Cnty',\", 1),\n",
       " (\"'172',\", 1),\n",
       " (\"'Mill',\", 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(r2[\"text\"]).split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = pd.read_csv('random3.csv')\n",
    "r3['Y/N'] = r3['Y/N'].astype(str)\n",
    "r3 = r3[r3['Y/N'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'ATXtraffic']\", 247),\n",
       " (\"'Austin',\", 173),\n",
       " (\"['Accident',\", 168),\n",
       " (\"'traffic',\", 107),\n",
       " (\"'back',\", 107),\n",
       " (\"'delay',\", 103),\n",
       " (\"'mins',\", 90),\n",
       " (\"'accident',\", 82),\n",
       " (\"'stop',\", 72),\n",
       " (\"'Blvd',\", 64),\n",
       " (\"'reported',\", 60),\n",
       " (\"'near',\", 43),\n",
       " (\"'Travis',\", 38),\n",
       " (\"'183',\", 34),\n",
       " (\"'cleared',\", 33),\n",
       " (\"['Serious',\", 31),\n",
       " (\"'Lamar',\", 31),\n",
       " (\"'Mopac',\", 31),\n",
       " (\"['Injury',\", 26),\n",
       " (\"['Major',\", 21),\n",
       " (\"'Hwy',\", 20),\n",
       " (\"'Ave',\", 20),\n",
       " (\"'290',\", 19),\n",
       " (\"'slow',\", 19),\n",
       " (\"'stopped',\", 18),\n",
       " (\"'Pkwy',\", 16),\n",
       " (\"'blocked',\", 15),\n",
       " (\"'left',\", 13),\n",
       " (\"'360',\", 12),\n",
       " (\"'Ben',\", 12),\n",
       " (\"'White',\", 12),\n",
       " (\"'approaching',\", 12),\n",
       " (\"'Service',\", 11),\n",
       " (\"'lane',\", 11),\n",
       " (\"'Oltorf',\", 10),\n",
       " (\"'min',\", 10),\n",
       " (\"'130',\", 9),\n",
       " (\"'Riverside',\", 9),\n",
       " (\"'Parmer',\", 9),\n",
       " (\"'973',\", 9),\n",
       " (\"'Anderson',\", 9),\n",
       " (\"'lanes',\", 9),\n",
       " (\"'2222',\", 9),\n",
       " (\"'William',\", 8),\n",
       " (\"'Cannon',\", 8),\n",
       " (\"'Pflugerville',\", 8),\n",
       " (\"'Rundberg',\", 8),\n",
       " (\"'Manor',\", 8),\n",
       " (\"'Slaughter',\", 8),\n",
       " (\"'1st',\", 8),\n",
       " (\"'Braker',\", 7),\n",
       " (\"'Grand',\", 7),\n",
       " (\"'Yager',\", 7),\n",
       " (\"'Airport',\", 7),\n",
       " (\"'51st',\", 7),\n",
       " (\"'Wells',\", 7),\n",
       " (\"'Branch',\", 7),\n",
       " (\"'45th',\", 7),\n",
       " (\"'Frontage',\", 7),\n",
       " (\"'Burnet',\", 6),\n",
       " (\"'Cesar',\", 6),\n",
       " (\"'Chavez',\", 6),\n",
       " (\"'Research',\", 6),\n",
       " (\"'two',\", 6),\n",
       " (\"'CedarPark',\", 5),\n",
       " (\"'Interstate',\", 5),\n",
       " (\"'ramp',\", 5),\n",
       " (\"'969',\", 5),\n",
       " (\"'Barton',\", 5),\n",
       " (\"'Springs',\", 5),\n",
       " (\"'due',\", 5),\n",
       " (\"'620',\", 5),\n",
       " (\"'Cameron',\", 5),\n",
       " (\"'Howard',\", 4),\n",
       " (\"'Bee',\", 4),\n",
       " (\"'Shelby',\", 4),\n",
       " (\"'Westover',\", 4),\n",
       " (\"'blocking',\", 4),\n",
       " (\"'812',\", 4),\n",
       " (\"'Guadalupe',\", 4),\n",
       " (\"'7th',\", 4),\n",
       " (\"'Boulevard',\", 4),\n",
       " (\"'Pecan',\", 4),\n",
       " (\"'Mill',\", 4),\n",
       " (\"'Far',\", 4),\n",
       " (\"'Stassney',\", 4),\n",
       " (\"'Rutland',\", 3),\n",
       " (\"'Loyola',\", 3),\n",
       " (\"'Johnny',\", 3),\n",
       " (\"'Morris',\", 3),\n",
       " (\"'Caves',\", 3),\n",
       " (\"'Woodland',\", 3),\n",
       " (\"'Bolm',\", 3),\n",
       " (\"'Justin',\", 3),\n",
       " (\"'Dessau',\", 3),\n",
       " (\"'Falls',\", 3),\n",
       " (\"'Crk',\", 3),\n",
       " (\"['Closed',\", 3),\n",
       " (\"'mins']\", 3),\n",
       " (\"'crash',\", 3),\n",
       " (\"'right',\", 3),\n",
       " (\"'NorthAustin',\", 3),\n",
       " (\"'Steck',\", 3),\n",
       " (\"'east',\", 3),\n",
       " (\"'Pky',\", 3),\n",
       " (\"'Park',\", 3),\n",
       " (\"'Harold',\", 3),\n",
       " (\"'Green',\", 3),\n",
       " (\"'Metric',\", 3),\n",
       " (\"'DelValle',\", 3),\n",
       " (\"'6th',\", 3),\n",
       " (\"'Skwy',\", 3),\n",
       " (\"'Westlake',\", 3),\n",
       " (\"'south',\", 3),\n",
       " (\"'Duval',\", 3),\n",
       " (\"'Congress',\", 3),\n",
       " (\"'Pass',\", 2),\n",
       " (\"'Hymeadow',\", 2),\n",
       " (\"'Farm',\", 2),\n",
       " (\"'Market',\", 2),\n",
       " (\"'15th',\", 2),\n",
       " (\"'1327',\", 2),\n",
       " (\"'Burleson',\", 2),\n",
       " (\"'McKinney',\", 2),\n",
       " (\"'Fairfield',\", 2),\n",
       " (\"'Bluestein',\", 2),\n",
       " (\"'Hills',\", 2),\n",
       " (\"'Rollingwood',\", 2),\n",
       " (\"'Enfield',\", 2),\n",
       " (\"'Trail',\", 2),\n",
       " (\"'Manchaca',\", 2),\n",
       " (\"'Brodie',\", 2),\n",
       " (\"'Martin',\", 2),\n",
       " (\"'Luther',\", 2),\n",
       " (\"'King',\", 2),\n",
       " (\"'scene',\", 2),\n",
       " (\"'collision',\", 2),\n",
       " (\"'8th',\", 2),\n",
       " (\"'38th',\", 2),\n",
       " (\"'AustinEastSide',\", 2),\n",
       " (\"'Mlk',\", 2),\n",
       " (\"'Creedmoor',\", 2),\n",
       " (\"'Spicewood',\", 2),\n",
       " (\"'Gregg',\", 2),\n",
       " (\"'Saint',\", 2),\n",
       " (\"'John',\", 2),\n",
       " (\"'time',\", 2),\n",
       " (\"'SouthAustin',\", 2),\n",
       " (\"'Woodward',\", 2),\n",
       " (\"'hit',\", 2),\n",
       " (\"'car',\", 2),\n",
       " (\"'Oak',\", 2),\n",
       " (\"'Bluff',\", 2),\n",
       " (\"'Old',\", 2),\n",
       " (\"'blocks',\", 2),\n",
       " (\"'three',\", 2),\n",
       " (\"'Mccallen',\", 1),\n",
       " (\"'Mcneil',\", 1),\n",
       " (\"'Pearce',\", 1),\n",
       " (\"['Quick',\", 1),\n",
       " (\"'ramentatsu_ya',\", 1),\n",
       " (\"'vegan',\", 1),\n",
       " (\"'ramen',\", 1),\n",
       " (\"'Yuzu',\", 1),\n",
       " (\"'Kosho',\", 1),\n",
       " (\"'bomb',\", 1),\n",
       " (\"'pictured']\", 1),\n",
       " (\"'Lakeline',\", 1),\n",
       " (\"'Ridgeline',\", 1),\n",
       " (\"'1826',\", 1),\n",
       " (\"'Gracy',\", 1),\n",
       " (\"'Farms',\", 1),\n",
       " (\"'Stonehollow',\", 1),\n",
       " (\"'2244',\", 1),\n",
       " (\"'Cuernavaca',\", 1),\n",
       " (\"'Grady',\", 1),\n",
       " (\"'Wickersham',\", 1),\n",
       " (\"'Techni',\", 1),\n",
       " (\"'Ctr',\", 1),\n",
       " (\"'Payton',\", 1),\n",
       " (\"'Central',\", 1),\n",
       " (\"'Commerce',\", 1),\n",
       " (\"'12th',\", 1),\n",
       " (\"'TravisCounty',\", 1),\n",
       " (\"'Dee',\", 1),\n",
       " (\"'Gabriel',\", 1),\n",
       " (\"'Collins',\", 1),\n",
       " (\"'Ross',\", 1),\n",
       " (\"'Navarro',\", 1),\n",
       " (\"'114',\", 1),\n",
       " (\"'Expy',\", 1),\n",
       " (\"'Sendero',\", 1),\n",
       " (\"'Great',\", 1),\n",
       " (\"'Gibson',\", 1),\n",
       " (\"['Medics',\", 1),\n",
       " (\"'head',\", 1),\n",
       " (\"'vehicle',\", 1),\n",
       " (\"'rescue',\", 1),\n",
       " (\"'Scenic',\", 1),\n",
       " (\"'Brook',\", 1),\n",
       " (\"'vehicles',\", 1),\n",
       " (\"'multiple']\", 1),\n",
       " (\"'Chicon',\", 1),\n",
       " (\"'Immanuel',\", 1),\n",
       " (\"'Turtle',\", 1),\n",
       " (\"'Rock',\", 1),\n",
       " (\"'Amasia',\", 1),\n",
       " (\"'Rio',\", 1),\n",
       " (\"'Grande',\", 1),\n",
       " (\"'Ohlen',\", 1),\n",
       " (\"'2769',\", 1),\n",
       " (\"'Bullick',\", 1),\n",
       " (\"'Hollow',\", 1),\n",
       " (\"'Koenig',\", 1),\n",
       " (\"'34th',\", 1),\n",
       " (\"'Berrywood',\", 1),\n",
       " (\"['ATX',\", 1),\n",
       " (\"'Traffic',\", 1),\n",
       " (\"'5200',\", 1),\n",
       " (\"'Blk',\", 1),\n",
       " (\"'West',\", 1),\n",
       " (\"'service',\", 1),\n",
       " (\"'road',\", 1),\n",
       " (\"'shut',\", 1),\n",
       " (\"'fatal',\", 1),\n",
       " (\"'WC2']\", 1),\n",
       " (\"'Bradbury',\", 1),\n",
       " (\"'Little',\", 1),\n",
       " (\"'Elm',\", 1),\n",
       " (\"'Thaxton',\", 1),\n",
       " (\"'1625',\", 1),\n",
       " (\"'Fincher',\", 1),\n",
       " (\"'Cypress',\", 1),\n",
       " (\"'29th',\", 1),\n",
       " (\"'Lower',\", 1),\n",
       " (\"'Deck',\", 1),\n",
       " (\"'Dean',\", 1),\n",
       " (\"'Keeton',\", 1),\n",
       " (\"['unfortunately',\", 1),\n",
       " (\"'also',\", 1),\n",
       " (\"'stupid']\", 1),\n",
       " (\"['That',\", 1),\n",
       " (\"'saw',\", 1),\n",
       " (\"'Wes',\", 1),\n",
       " (\"'Bill',\", 1),\n",
       " (\"'Murray',\", 1),\n",
       " (\"'premier',\", 1),\n",
       " (\"'isleofdogs',\", 1),\n",
       " (\"'sxsw',\", 1),\n",
       " (\"'livingthedream']\", 1),\n",
       " (\"['First',\", 1),\n",
       " (\"'private',\", 1),\n",
       " (\"'event',\", 1),\n",
       " (\"'may',\", 1),\n",
       " (\"'last']\", 1),\n",
       " (\"'Mary',\", 1),\n",
       " (\"'Rosewood',\", 1),\n",
       " (\"'west',\", 1),\n",
       " (\"'Hargrave',\", 1),\n",
       " (\"'shoulder',\", 1),\n",
       " (\"'Lakeway',\", 1),\n",
       " (\"'Debba',\", 1),\n",
       " (\"'General',\", 1),\n",
       " (\"'Williamson',\", 1),\n",
       " (\"'Barstow',\", 1),\n",
       " (\"['Fatality',\", 1),\n",
       " (\"'Frate',\", 1),\n",
       " (\"'Barker',\", 1),\n",
       " (\"'Serv',\", 1),\n",
       " (\"'Westbank',\", 1),\n",
       " (\"'Toll',\", 1),\n",
       " (\"'24th',\", 1),\n",
       " (\"'express',\", 1),\n",
       " (\"'Caves']\", 1),\n",
       " (\"'rollover',\", 1),\n",
       " (\"'Pfulgerville',\", 1),\n",
       " (\"'5th',\", 1),\n",
       " (\"'Pleasant',\", 1),\n",
       " (\"'Vly',\", 1),\n",
       " (\"'center',\", 1),\n",
       " (\"'ambulance',\", 1),\n",
       " (\"'different',\", 1),\n",
       " (\"'truck',\", 1),\n",
       " (\"'AshleyG_KVUE']\", 1),\n",
       " (\"['Rollover',\", 1),\n",
       " (\"'Fitzhugh',\", 1),\n",
       " (\"'Hudson',\", 1),\n",
       " (\"'Bend',\", 1),\n",
       " (\"'Beacon',\", 1),\n",
       " (\"'Reserach',\", 1),\n",
       " (\"'Knoll',\", 1),\n",
       " (\"'Live',\", 1),\n",
       " (\"['atxtraffic',\", 1),\n",
       " (\"'5000',\", 1),\n",
       " (\"'one',\", 1),\n",
       " (\"'Please',\", 1),\n",
       " (\"'avoid',\", 1),\n",
       " (\"'area',\", 1),\n",
       " (\"'WC4',\", 1),\n",
       " (\"'Austin_Police']\", 1),\n",
       " (\"'Payload',\", 1),\n",
       " (\"'Twin',\", 1),\n",
       " (\"'Creeks',\", 1),\n",
       " (\"'Club',\", 1),\n",
       " (\"'Quicksilver',\", 1),\n",
       " (\"'Decker',\", 1),\n",
       " (\"'Montopolis',\", 1),\n",
       " (\"'Reinli',\", 1),\n",
       " (\"'Onion',\", 1),\n",
       " (\"'Kimbro',\", 1),\n",
       " (\"'Broadmoor',\", 1),\n",
       " (\"['Mainlanes',\", 1),\n",
       " (\"'investigation',\", 1),\n",
       " (\"'work',\", 1),\n",
       " (\"'Albert',\", 1),\n",
       " (\"'Brown',\", 1),\n",
       " (\"'35th',\", 1),\n",
       " (\"'fuel',\", 1),\n",
       " (\"'spill',\", 1),\n",
       " (\"'1626',\", 1),\n",
       " (\"'San',\", 1),\n",
       " (\"'Antonio',\", 1),\n",
       " (\"'Brentwood',\", 1),\n",
       " (\"'Brandt',\", 1),\n",
       " (\"'Middle',\", 1),\n",
       " (\"'Capitol',\", 1),\n",
       " (\"'Cross',\", 1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(r3[\"text\"]).split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = pd.read_csv('random4.csv')\n",
    "r4['Y/N'] = r4['Y/N'].astype(str)\n",
    "r4 = r4[r4['Y/N'] == 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'ATXtraffic']\", 256),\n",
       " (\"'Austin',\", 204),\n",
       " (\"['Accident',\", 175),\n",
       " (\"'traffic',\", 117),\n",
       " (\"'back',\", 117),\n",
       " (\"'delay',\", 109),\n",
       " (\"'accident',\", 88),\n",
       " (\"'mins',\", 86),\n",
       " (\"'stop',\", 85),\n",
       " (\"'Blvd',\", 59),\n",
       " (\"'reported',\", 53),\n",
       " (\"'near',\", 51),\n",
       " (\"'183',\", 44),\n",
       " (\"['Serious',\", 39),\n",
       " (\"'Travis',\", 35),\n",
       " (\"'Lamar',\", 31),\n",
       " (\"'cleared',\", 30),\n",
       " (\"['Injury',\", 27),\n",
       " (\"'Hwy',\", 23),\n",
       " (\"'approaching',\", 22),\n",
       " (\"'Ave',\", 21),\n",
       " (\"'blocked',\", 20),\n",
       " (\"'Mopac',\", 20),\n",
       " (\"'360',\", 19),\n",
       " (\"'lane',\", 19),\n",
       " (\"['Major',\", 18),\n",
       " (\"'slow',\", 18),\n",
       " (\"'Pkwy',\", 16),\n",
       " (\"'min',\", 16),\n",
       " (\"'right',\", 14),\n",
       " (\"'stopped',\", 14),\n",
       " (\"'Braker',\", 14),\n",
       " (\"'290',\", 13),\n",
       " (\"'Burnet',\", 12),\n",
       " (\"'2222',\", 12),\n",
       " (\"'Howard',\", 11),\n",
       " (\"'Ben',\", 11),\n",
       " (\"'White',\", 11),\n",
       " (\"'left',\", 11),\n",
       " (\"'Cesar',\", 10),\n",
       " (\"'Chavez',\", 10),\n",
       " (\"'51st',\", 10),\n",
       " (\"'Service',\", 10),\n",
       " (\"'Riverside',\", 9),\n",
       " (\"'Pflugerville',\", 9),\n",
       " (\"'William',\", 9),\n",
       " (\"'Cannon',\", 9),\n",
       " (\"'Boulevard',\", 9),\n",
       " (\"'Wells',\", 8),\n",
       " (\"'Branch',\", 8),\n",
       " (\"'Anderson',\", 8),\n",
       " (\"'Parmer',\", 8),\n",
       " (\"'Oltorf',\", 8),\n",
       " (\"'Rundberg',\", 7),\n",
       " (\"'mins']\", 7),\n",
       " (\"'Steck',\", 7),\n",
       " (\"'Stassney',\", 6),\n",
       " (\"'Frontage',\", 6),\n",
       " (\"'Manor',\", 6),\n",
       " (\"'Woodward',\", 6),\n",
       " (\"'Cameron',\", 6),\n",
       " (\"'Slaughter',\", 6),\n",
       " (\"'east',\", 6),\n",
       " (\"'Bee',\", 6),\n",
       " (\"'Caves',\", 6),\n",
       " (\"'Grand',\", 6),\n",
       " (\"'Airport',\", 5),\n",
       " (\"'12th',\", 5),\n",
       " (\"'Yager',\", 5),\n",
       " (\"'lanes',\", 5),\n",
       " (\"'130',\", 5),\n",
       " (\"'shoulder',\", 5),\n",
       " (\"'1st',\", 4),\n",
       " (\"'Springdale',\", 4),\n",
       " (\"'7th',\", 4),\n",
       " (\"'Mcneil',\", 4),\n",
       " (\"'west',\", 4),\n",
       " (\"'969',\", 4),\n",
       " (\"'620',\", 4),\n",
       " (\"'1327',\", 4),\n",
       " (\"'Loyola',\", 4),\n",
       " (\"'Interstate',\", 4),\n",
       " (\"'973',\", 4),\n",
       " (\"'Shelby',\", 4),\n",
       " (\"'two',\", 4),\n",
       " (\"'south',\", 4),\n",
       " (\"'Mill',\", 4),\n",
       " (\"['Overturned',\", 4),\n",
       " (\"'vehicle',\", 4),\n",
       " (\"'Heatherwilde',\", 3),\n",
       " (\"'1626',\", 3),\n",
       " (\"'Westbank',\", 3),\n",
       " (\"'Oak',\", 3),\n",
       " (\"'Knoll',\", 3),\n",
       " (\"'Research',\", 3),\n",
       " (\"'Springs',\", 3),\n",
       " (\"'Dean',\", 3),\n",
       " (\"'Keeton',\", 3),\n",
       " (\"'Woodland',\", 3),\n",
       " (\"'Manchaca',\", 3),\n",
       " (\"'Congress',\", 3),\n",
       " (\"'Pecan',\", 3),\n",
       " (\"'blocking',\", 3),\n",
       " (\"'Dessau',\", 3),\n",
       " (\"'Reinli',\", 3),\n",
       " (\"'Dee',\", 3),\n",
       " (\"'Gabriel',\", 3),\n",
       " (\"'Collins',\", 3),\n",
       " (\"'2244',\", 3),\n",
       " (\"'Pky',\", 3),\n",
       " (\"'Martin',\", 3),\n",
       " (\"'Luther',\", 3),\n",
       " (\"'King',\", 3),\n",
       " (\"'Crk',\", 3),\n",
       " (\"'Koenig',\", 3),\n",
       " (\"'Barton',\", 3),\n",
       " (\"'Rollingwood',\", 3),\n",
       " (\"'1825',\", 2),\n",
       " (\"'Demaret',\", 2),\n",
       " (\"'Walsh',\", 2),\n",
       " (\"'Tarlton',\", 2),\n",
       " (\"'Montopolis',\", 2),\n",
       " (\"'Capital',\", 2),\n",
       " (\"'Texas',\", 2),\n",
       " (\"'Spicewood',\", 2),\n",
       " (\"'29th',\", 2),\n",
       " (\"'Lower',\", 2),\n",
       " (\"'Deck',\", 2),\n",
       " (\"'Saint',\", 2),\n",
       " (\"'Far',\", 2),\n",
       " (\"'Convict',\", 2),\n",
       " (\"'Johnny',\", 2),\n",
       " (\"'Morris',\", 2),\n",
       " (\"'Brodie',\", 2),\n",
       " (\"'gets',\", 2),\n",
       " (\"'11th',\", 2),\n",
       " (\"'Rdg',\", 2),\n",
       " (\"'RoundRock',\", 2),\n",
       " (\"'Metric',\", 2),\n",
       " (\"'Mccall',\", 2),\n",
       " (\"'Burleson',\", 2),\n",
       " (\"'Mckenzie',\", 2),\n",
       " (\"'Duval',\", 2),\n",
       " (\"'Justin',\", 2),\n",
       " (\"'35th',\", 2),\n",
       " (\"'15th',\", 2),\n",
       " (\"'Toll',\", 2),\n",
       " (\"'Old',\", 2),\n",
       " (\"'ramp',\", 2),\n",
       " (\"'crash',\", 2),\n",
       " (\"'BeeCave',\", 2),\n",
       " (\"'Hamilton',\", 2),\n",
       " (\"'Pool',\", 2),\n",
       " (\"'8th',\", 2),\n",
       " (\"['Closed',\", 2),\n",
       " (\"'due',\", 2),\n",
       " (\"'Enfield',\", 2),\n",
       " (\"'Burch',\", 2),\n",
       " (\"'45th',\", 2),\n",
       " (\"'Westover',\", 2),\n",
       " (\"'Trinity',\", 1),\n",
       " (\"'investigation',\", 1),\n",
       " (\"'work',\", 1),\n",
       " (\"'Bolm',\", 1),\n",
       " (\"'Gardner',\", 1),\n",
       " (\"'34th',\", 1),\n",
       " (\"'2001',\", 1),\n",
       " (\"'Todd',\", 1),\n",
       " (\"'Elmo',\", 1),\n",
       " (\"'Morrow',\", 1),\n",
       " (\"'Amherst',\", 1),\n",
       " (\"'Bluestein',\", 1),\n",
       " (\"'Park',\", 1),\n",
       " (\"'Imperial',\", 1),\n",
       " (\"'Escarpment',\", 1),\n",
       " (\"'Webberville',\", 1),\n",
       " (\"'Svc',\", 1),\n",
       " (\"'Payton',\", 1),\n",
       " (\"'Gin',\", 1),\n",
       " (\"'exit',\", 1),\n",
       " (\"'AustinEastSide',\", 1),\n",
       " (\"'Brandt',\", 1),\n",
       " (\"'Ctr',\", 1),\n",
       " (\"'John',\", 1),\n",
       " (\"'1826',\", 1),\n",
       " (\"'Thompson',\", 1),\n",
       " (\"'Bonnell',\", 1),\n",
       " (\"'Hesters']\", 1),\n",
       " (\"'Cuernavaca',\", 1),\n",
       " (\"'Nueces',\", 1),\n",
       " (\"'9th',\", 1),\n",
       " (\"'Windsor',\", 1),\n",
       " (\"'Teasdale',\", 1),\n",
       " (\"'Ter',\", 1),\n",
       " (\"'service',\", 1),\n",
       " (\"'Sitio',\", 1),\n",
       " (\"'del',\", 1),\n",
       " (\"'Rio',\", 1),\n",
       " (\"'clear',\", 1),\n",
       " (\"'Mlk',\", 1),\n",
       " (\"'involving',\", 1),\n",
       " (\"'overturned',\", 1),\n",
       " (\"'wheeler',\", 1),\n",
       " (\"'Manor']\", 1),\n",
       " (\"'Annie',\", 1),\n",
       " (\"'Sendero',\", 1),\n",
       " (\"'Hills',\", 1),\n",
       " (\"'NorthAustin',\", 1),\n",
       " (\"'Waymaker',\", 1),\n",
       " (\"'Owen',\", 1),\n",
       " (\"'Tech',\", 1),\n",
       " (\"'NorthwestAustinArboretumArea',\", 1),\n",
       " (\"'Albert',\", 1),\n",
       " (\"'Brown',\", 1),\n",
       " (\"'DrippingSprings',\", 1),\n",
       " (\"'Broadmoor',\", 1),\n",
       " (\"'1100',\", 1),\n",
       " (\"'Neches',\", 1),\n",
       " (\"'6th',\", 1),\n",
       " (\"'Onion',\", 1),\n",
       " (\"'Ferguson',\", 1),\n",
       " (\"'Sprinkle',\", 1),\n",
       " (\"'3406',\", 1),\n",
       " (\"'McNeil',\", 1),\n",
       " (\"'north',\", 1),\n",
       " (\"'Steiner',\", 1),\n",
       " (\"'Ranch',\", 1),\n",
       " (\"['RRTraffic',\", 1),\n",
       " (\"'Working',\", 1),\n",
       " (\"'major',\", 1),\n",
       " (\"'rollover',\", 1),\n",
       " (\"'vehicles',\", 1),\n",
       " (\"'involved',\", 1),\n",
       " (\"'transported',\", 1),\n",
       " (\"'100',\", 1),\n",
       " (\"'blk',\", 1),\n",
       " (\"'Louis',\", 1),\n",
       " (\"'Henna',\", 1),\n",
       " (\"'lanes']\", 1),\n",
       " (\"['Fatality',\", 1),\n",
       " (\"'Industrial',\", 1),\n",
       " (\"'Oaks',\", 1),\n",
       " (\"['Possible',\", 1),\n",
       " (\"'fatality',\", 1),\n",
       " (\"'138',\", 1),\n",
       " (\"'one',\", 1),\n",
       " (\"'Creeks',\", 1),\n",
       " (\"'Edge',\", 1),\n",
       " (\"'Palomino',\", 1),\n",
       " (\"'stop']\", 1),\n",
       " (\"'Ross',\", 1),\n",
       " (\"'State',\", 1),\n",
       " (\"'Red',\", 1),\n",
       " (\"'River',\", 1),\n",
       " (\"'Rainey',\", 1),\n",
       " (\"'Driskill',\", 1),\n",
       " (\"'Alexander',\", 1),\n",
       " (\"'38th',\", 1),\n",
       " (\"'Guadalupe',\", 1),\n",
       " (\"'Garfield',\", 1),\n",
       " (\"'Buck',\", 1),\n",
       " (\"'Pkwy']\", 1),\n",
       " (\"'Farm',\", 1),\n",
       " (\"'Market',\", 1),\n",
       " (\"'685',\", 1),\n",
       " (\"['APD',\", 1),\n",
       " (\"'enroute',\", 1),\n",
       " (\"'Rockwood',\", 1),\n",
       " (\"'Avoid',\", 1),\n",
       " (\"'area',\", 1),\n",
       " (\"'WC1',\", 1),\n",
       " (\"'atxtraffic',\", 1),\n",
       " (\"'Austin_Police']\", 1),\n",
       " (\"'Mary',\", 1),\n",
       " (\"'Ponciana',\", 1),\n",
       " (\"'Hymeadow',\", 1),\n",
       " (\"'Knollwood',\", 1),\n",
       " (\"'Parkfield',\", 1),\n",
       " (\"'Decker',\", 1),\n",
       " (\"'Arboretum',\", 1),\n",
       " (\"'Skwy',\", 1),\n",
       " (\"'southbound',\", 1),\n",
       " (\"'Rutland',\", 1),\n",
       " (\"'Thornberry',\", 1),\n",
       " (\"'Pleasant',\", 1),\n",
       " (\"'Vly',\", 1),\n",
       " (\"'Elmont',\", 1),\n",
       " (\"'Zilker',\", 1),\n",
       " (\"'Clubhouse',\", 1),\n",
       " (\"'Willow',\", 1),\n",
       " (\"'Elroy',\", 1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(r4[\"text\"]).split()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['ATXtraffic','Accident','traffic','back','delay','accident','mins','stop','Blvd','reported',\\\n",
    "        'near','183','Serious','Travis','Lamar','cleared','Injury','Hwy','cleared','Major']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "r2 = pd.read_csv('random2.csv',index_col=0)\n",
    "r3 = pd.read_csv('random3.csv',index_col=0)\n",
    "r4 = pd.read_csv('random4.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([r2,r3,r4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2973, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features <br>\n",
    "- Time of the day <br>\n",
    "- User/organizaion <br>\n",
    "- words(unigrams/bigrams) <br>\n",
    "- hashtags <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
