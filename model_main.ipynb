{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN - for one link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Avg_travel_time</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>51st_mueller</td>\n",
       "      <td>51st_manor</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>51st_mueller</td>\n",
       "      <td>51st_manor</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>51st_mueller</td>\n",
       "      <td>51st_manor</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>51st_mueller</td>\n",
       "      <td>51st_manor</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>51st_mueller</td>\n",
       "      <td>51st_manor</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Avg_travel_time   Destination      Origin  Time  Weekday  Year\n",
       "0      0              217  51st_mueller  51st_manor     0        0  2015\n",
       "1      1              176  51st_mueller  51st_manor    15        0  2015\n",
       "2      2              180  51st_mueller  51st_manor    30        0  2015\n",
       "3      3              175  51st_mueller  51st_manor    45        0  2015\n",
       "4      4              176  51st_mueller  51st_manor    60        0  2015"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import csv # csv module\n",
    "import tensorflow as tf # Tensorflow module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_Destination = '51st_springdale'\n",
    "route_origin = '51st_manor'\n",
    "df['Time'] = df['Time'].astype(int)\n",
    "df[(df['Destination'] == route_Destination) & (df['Origin'] == route_origin)].to_csv('route.csv')\n",
    "df1 = pd.read_csv('route.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = []\n",
    "training_set_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zone, codedday, codedweather, temperature, realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df1.sample(frac=0.9, random_state=99)\n",
    "df_test = df1.loc[~df1.index.isin(df_train.index), :]\n",
    "df_train.to_csv('route_train.csv')\n",
    "df_test.to_csv('route_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing Training Data set \n",
    "# Extracting each parameter into different list.\n",
    "with open(\"route_train.csv\",\"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        training_set.append([row[6],row[7],row[8]])\n",
    "        training_set_y.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the first column from the list (which is nothing but name column)\n",
    "training_set = training_set[1:]\n",
    "training_set_y = training_set_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = []\n",
    "testing_set_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"route_test.csv\",\"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        testing_set.append([row[6],row[7],row[8]])\n",
    "        testing_set_y.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the first column from the list (which is nothing but name column)\n",
    "testing_set = testing_set[1:]\n",
    "testing_set_y = testing_set_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder you can assign values in future its kind of a variable\n",
    "#  v = (\"variable type\",None) -- You can assign any number of variables for v\n",
    "#  v = (\"variable type\",4)    -- You can assign 4 variables for v\n",
    "#  v = (\"variable type\",[None,4])  -- you can have multidimensional values here \n",
    "# Here the no.of rows you can have any number but the columns are fixed with size 4\n",
    "training_values = tf.placeholder(\"float\",[None,len(training_set[0])])\n",
    "test_values     = tf.placeholder(\"float\",[len(training_set[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the distance formula to calculate the distance between the test values and the training values\n",
    "distance = tf.reduce_sum(tf.abs(tf.add(training_values,tf.negative(test_values))),reduction_indices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-da47ba9d6402>:2: arg_min (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmin` instead\n"
     ]
    }
   ],
   "source": [
    "# Returns the index with the smallest value across dimensions of a tensor\n",
    "prediction = tf.arg_min(distance,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/manojgedela/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Initializing  the session\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0\n",
      "Test 1\n",
      "Test 2\n",
      "Test 3\n",
      "Test 4\n",
      "Test 5\n",
      "Test 6\n",
      "Test 7\n",
      "Test 8\n",
      "Test 9\n",
      "Test 10\n",
      "Test 11\n",
      "Test 12\n",
      "Test 13\n",
      "Test 14\n",
      "Test 15\n",
      "Test 16\n",
      "Test 17\n",
      "Test 18\n",
      "Test 19\n",
      "Test 20\n",
      "Test 21\n",
      "Test 22\n",
      "Test 23\n",
      "Test 24\n",
      "Test 25\n",
      "Test 26\n",
      "Test 27\n",
      "Test 28\n",
      "Test 29\n",
      "Test 30\n",
      "Test 31\n",
      "Test 32\n",
      "Test 33\n",
      "Test 34\n",
      "Test 35\n",
      "Test 36\n",
      "Test 37\n",
      "Test 38\n",
      "Test 39\n",
      "Test 40\n",
      "Test 41\n",
      "Test 42\n",
      "Test 43\n",
      "Test 44\n",
      "Test 45\n",
      "Test 46\n",
      "Test 47\n",
      "Test 48\n",
      "Test 49\n",
      "Test 50\n",
      "Test 51\n",
      "Test 52\n",
      "Test 53\n",
      "Test 54\n",
      "Test 55\n",
      "Test 56\n",
      "Test 57\n",
      "Test 58\n",
      "Test 59\n",
      "Test 60\n",
      "Test 61\n",
      "Test 62\n",
      "Test 63\n",
      "Test 64\n",
      "Test 65\n",
      "Test 66\n",
      "Test 67\n",
      "Test 68\n",
      "Test 69\n",
      "Test 70\n",
      "Test 71\n",
      "Test 72\n",
      "Test 73\n",
      "Test 74\n",
      "Test 75\n",
      "Test 76\n",
      "Test 77\n",
      "Test 78\n",
      "Test 79\n",
      "Test 80\n",
      "Test 81\n",
      "Test 82\n",
      "Test 83\n",
      "Test 84\n",
      "Test 85\n",
      "Test 86\n",
      "Test 87\n",
      "Test 88\n",
      "Test 89\n",
      "Test 90\n",
      "Test 91\n",
      "Test 92\n",
      "Test 93\n",
      "Test 94\n",
      "Test 95\n",
      "Test 96\n",
      "Test 97\n",
      "Test 98\n",
      "Test 99\n",
      "Test 100\n",
      "Test 101\n",
      "Test 102\n",
      "Test 103\n",
      "Test 104\n",
      "Test 105\n",
      "Test 106\n",
      "Test 107\n",
      "Test 108\n",
      "Test 109\n",
      "Test 110\n",
      "Test 111\n",
      "Test 112\n",
      "Test 113\n",
      "Test 114\n",
      "Test 115\n",
      "Test 116\n",
      "Test 117\n",
      "Test 118\n",
      "Test 119\n",
      "Test 120\n",
      "Test 121\n",
      "Test 122\n",
      "Test 123\n",
      "Test 124\n",
      "Test 125\n",
      "Test 126\n",
      "Test 127\n",
      "Test 128\n",
      "Test 129\n",
      "Test 130\n",
      "Test 131\n",
      "Test 132\n",
      "Test 133\n",
      "Test 134\n",
      "Test 135\n",
      "Test 136\n",
      "Test 137\n",
      "Test 138\n",
      "Test 139\n",
      "Test 140\n",
      "Test 141\n",
      "Test 142\n",
      "Test 143\n",
      "Test 144\n",
      "Test 145\n",
      "Test 146\n",
      "Test 147\n",
      "Test 148\n",
      "Test 149\n",
      "Test 150\n",
      "Test 151\n",
      "Test 152\n",
      "Test 153\n",
      "Test 154\n",
      "Test 155\n",
      "Test 156\n",
      "Test 157\n",
      "Test 158\n",
      "Test 159\n",
      "Test 160\n",
      "Test 161\n",
      "Test 162\n",
      "Test 163\n",
      "Test 164\n",
      "Test 165\n",
      "Test 166\n",
      "Test 167\n",
      "Test 168\n",
      "Test 169\n",
      "Test 170\n",
      "Test 171\n",
      "Test 172\n",
      "Test 173\n",
      "Test 174\n",
      "Test 175\n",
      "Test 176\n",
      "Test 177\n",
      "Test 178\n",
      "Test 179\n",
      "Test 180\n",
      "Test 181\n",
      "Test 182\n",
      "Test 183\n",
      "Test 184\n",
      "Test 185\n",
      "Test 186\n"
     ]
    }
   ],
   "source": [
    "# Starting the calculation process\n",
    "# For every test sample, the above \"distance\" formula will get called and the distance formula will return the \n",
    "# distances from the traning set values to the test sample and then the \"prediction\" will return the smallest \n",
    "# distance index\n",
    "list1 = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # Looping through the test set to compare against the training set\n",
    "    for i in range (len(testing_set)):\n",
    "        # Tensor flow method to get the prediction nearer to the test parameters from the training set.\n",
    "        index_in_trainingset = sess.run(prediction,feed_dict={training_values:training_set,test_values:testing_set[i]})\n",
    "        print (\"Test %d\" %(i))\n",
    "        list1.append(training_set_y[index_in_trainingset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_predicted = []\n",
    "travel_time_predicted = list1\n",
    "travel_time_actual = []\n",
    "travel_time_actual = df_test['Avg_travel_time'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.670006413360732"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "travel_time_actual = [int(i) for i in travel_time_actual]\n",
    "travel_time_predicted = [int(i) for i in travel_time_predicted]\n",
    "r2_score(travel_time_actual,travel_time_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.27272727272727"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(travel_time_actual,travel_time_predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6692776223684695"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(travel_time_actual,travel_time_predicted)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.663101604278076"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "mean_absolute_percentage_error(travel_time_actual,travel_time_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - for one link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('route.csv')\n",
    "df = df.dropna(inplace=False)\n",
    "df = df.drop(['Destination','Origin','index','Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg_travel_time</th>\n",
       "      <th>Time</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg_travel_time  Time  Weekday  Year\n",
       "0               76     0        0  2015\n",
       "1               70    15        0  2015\n",
       "2               71    30        0  2015\n",
       "3               78    45        0  2015\n",
       "4               76    60        0  2015"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,1:4]\n",
    "Y = dataset[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -631.77 (1604.82) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manojgedela/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -72.16 (45.15) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=3, kernel_initializer='normal', activation='relu')) # input layer; size 3\n",
    "    model.add(Dense(6, kernel_initializer='normal', activation='relu')) # hidden layer; size 6\n",
    "    model.add(Dense(1, kernel_initializer='normal')) # output layer; size 1 with no activation since it's a regression problem\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -72.92 (45.84) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluation on the larger net\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(6, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -71.75 (45.07) MSE\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####prediction#####\n",
    "# Run prediction model on the above case\n",
    "#pipeline.fit(X,Y) # Fit model\n",
    "#Y_pred = pipeline.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
